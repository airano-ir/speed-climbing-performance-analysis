# Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„: Calibration Ùˆ Frame Selection Ø¯Ø± Metrics

**ØªØ§Ø±ÛŒØ®**: 2025-11-15
**Ù…Ø®Ø§Ø·Ø¨**: ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ú¯Ø§Ù†ØŒ Ù…Ø­Ù‚Ù‚Ø§Ù†ØŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI
**Ø³Ø·Ø­**: Ù…ØªÙˆØ³Ø· ØªØ§ Ù¾ÛŒØ´Ø±ÙØªÙ‡
**Ø²Ù…Ø§Ù† Ù…Ø·Ø§Ù„Ø¹Ù‡**: 30-45 Ø¯Ù‚ÛŒÙ‚Ù‡

---

## ğŸ“š ÙÙ‡Ø±Ø³Øª Ù…Ø·Ø§Ù„Ø¨

1. [Ù…Ù‚Ø¯Ù…Ù‡](#Ù…Ù‚Ø¯Ù…Ù‡)
2. [Ø¨Ø®Ø´ 1: Ú†Ø±Ø§ Calibration Ù„Ø§Ø²Ù… Ø§Ø³ØªØŸ](#Ø¨Ø®Ø´-1-Ú†Ø±Ø§-calibration-Ù„Ø§Ø²Ù…-Ø§Ø³Øª)
3. [Ø¨Ø®Ø´ 2: Ú†Ø±Ø§ Frame Selection Ù…Ù‡Ù… Ø§Ø³ØªØŸ](#Ø¨Ø®Ø´-2-Ú†Ø±Ø§-frame-selection-Ù…Ù‡Ù…-Ø§Ø³Øª)
4. [Ø¨Ø®Ø´ 3: Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø³ÛŒØ³ØªÙ…](#Ø¨Ø®Ø´-3-Ù…Ø¹Ù…Ø§Ø±ÛŒ-Ø³ÛŒØ³ØªÙ…)
5. [Ø¨Ø®Ø´ 4: Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„](#Ø¨Ø®Ø´-4-Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ-Ú©Ø§Ù…Ù„)
6. [Ø¨Ø®Ø´ 5: ØªØ³Øª Ùˆ Validation](#Ø¨Ø®Ø´-5-ØªØ³Øª-Ùˆ-validation)
7. [Ø¨Ø®Ø´ 6: Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ](#Ø¨Ø®Ø´-6-Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ)
8. [Ø¨Ø®Ø´ 7: Ù†Ú©Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡](#Ø¨Ø®Ø´-7-Ù†Ú©Ø§Øª-Ù¾ÛŒØ´Ø±ÙØªÙ‡)

---

## Ù…Ù‚Ø¯Ù…Ù‡

### Ù‡Ø¯Ù Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§

Ø¯Ø± ØªØ³Øª Phase 3 Ù¾Ø±ÙˆÚ˜Ù‡ ØªØ­Ù„ÛŒÙ„ Ø³Ù†Ú¯Ù†ÙˆØ±Ø¯ÛŒ Ø³Ø±Ø¹ØªÛŒØŒ Ø¯Ùˆ Ù…Ø´Ú©Ù„ Ø¨Ø­Ø±Ø§Ù†ÛŒ Ú©Ø´Ù Ø´Ø¯ Ú©Ù‡ validity Ù‡Ù…Ù‡ metrics Ø±Ø§ Ø²ÛŒØ± Ø³ÙˆØ§Ù„ Ø¨Ø±Ø¯:

1. **Ø¹Ø¯Ù… Calibration**: metrics Ø¯Ø± pixel Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ØŒ Ù†Ù‡ meter
2. **Ø¹Ø¯Ù… Frame Selection**: ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯ Ù…Ø³Ø§Ø¨Ù‚Ù‡ Ù‡Ù… Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ù‡Ø³ØªÙ†Ø¯

Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ú©Ø§Ù…Ù„ ØªÙˆØ¶ÛŒØ­ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯:
- **Ú†Ø±Ø§** Ø§ÛŒÙ† Ù…Ø´Ú©Ù„Ø§Øª Ø¨Ø­Ø±Ø§Ù†ÛŒ Ù‡Ø³ØªÙ†Ø¯
- **Ú†Ú¯ÙˆÙ†Ù‡** Ø¨Ø§ÛŒØ¯ Ø±ÙØ¹ Ø´ÙˆÙ†Ø¯
- **Ú†Ø·ÙˆØ±** Ø³ÛŒØ³ØªÙ… Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯

---

## Ø¨Ø®Ø´ 1: Ú†Ø±Ø§ Calibration Ù„Ø§Ø²Ù… Ø§Ø³ØªØŸ

### 1.1. Ù…ÙÙ‡ÙˆÙ… Calibration

**Calibration** ÛŒØ¹Ù†ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…Ø®ØªØµØ§Øª **pixel** (ÙˆØ§Ø­Ø¯ ØªØµÙˆÛŒØ±) Ø¨Ù‡ Ù…Ø®ØªØµØ§Øª **meter** (ÙˆØ§Ø­Ø¯ ÙÛŒØ²ÛŒÚ©ÛŒ).

```
WITHOUT Calibration:
Pixel (480, 320) â†’ ??? meters

WITH Calibration:
Pixel (480, 320) â†’ (1.2m, 8.5m) in real world
```

---

### 1.2. Ú†Ø±Ø§ Ø¯Ø± Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ CRITICAL Ø§Ø³ØªØŸ

#### Ù…Ø´Ú©Ù„ 1: Ø¯ÙˆØ±Ø¨ÛŒÙ† Ù…ØªØ­Ø±Ú© (Moving Camera)

**ÙˆÛŒØ¯Ø¦ÙˆÙ‡Ø§ÛŒ IFSC**:
- Ø¯ÙˆØ±Ø¨ÛŒÙ† Ø³Ù†Ú¯Ù†ÙˆØ±Ø¯ Ø±Ø§ Ø¯Ù†Ø¨Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (pan + zoom)
- Ø¯Ø± Ø´Ø±ÙˆØ¹ Ù…Ø³Ø§Ø¨Ù‚Ù‡: Ø¯ÛŒØ¯ wide (Ú©Ù„ Ø¯ÛŒÙˆØ§Ø±) â†’ Ù…Ù‚ÛŒØ§Ø³ Ú©ÙˆÚ†Ú©
- Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ÛŒ Ù…Ø³Ø§Ø¨Ù‚Ù‡: zoom Ø±ÙˆÛŒ climber â†’ Ù…Ù‚ÛŒØ§Ø³ Ø¨Ø²Ø±Ú¯

**Ù…Ø«Ø§Ù„ ÙˆØ§Ù‚Ø¹ÛŒ**:
```
Frame 1 (start - wide view):
  Climber height in image: 100 pixels
  Actual height: 1.7m
  Scale: 1 pixel = 1.7cm

Frame 143 (finish - zoomed in):
  Climber height in image: 300 pixels
  Actual height: 1.7m (unchanged!)
  Scale: 1 pixel = 0.57cm (3Ã— smaller!)
```

**ØªØ§Ø«ÛŒØ± Ø±ÙˆÛŒ velocity**:
```python
# WITHOUT calibration (WRONG):
v_pixel = (y2 - y1) / dt
# Frame 1â†’50: v = 10 px/s
# Frame 100â†’143: v = 30 px/s (3Ã— Ø¨ÛŒØ´ØªØ± Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ zoom!)
# Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†: 20 px/s

# PROBLEM: Ø§ÛŒÙ† Ø³Ø±Ø¹Øª Ú†Ù‚Ø¯Ø± Ø³Ø±ÛŒØ¹ Ø§Ø³ØªØŸ Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…!

# WITH calibration (CORRECT):
v_meter = calibration.pixel_to_meter(y2) - calibration.pixel_to_meter(y1)) / dt
# Ù‡Ù…Ù‡ frames: v â‰ˆ 2.3 m/s (Ø«Ø§Ø¨Øª - Ø¯Ø±Ø³Øª!)
```

**Ù†ØªÛŒØ¬Ù‡**: **Ø¨Ø¯ÙˆÙ† calibrationØŒ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† velocity Ù…Ø¹ØªØ¨Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø±Ø¯!**

---

#### Ù…Ø´Ú©Ù„ 2: Ø¹Ø¯Ù… Ù‚Ø§Ø¨Ù„ÛŒØª Ù…Ù‚Ø§ÛŒØ³Ù‡

**Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨ÛŒÙ† races**:
```
Race A (Seoul):
  Camera distance: 20 meters
  Velocity: 25 px/s

Race B (Chamonix):
  Camera distance: 15 meters (Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±!)
  Velocity: 35 px/s

Ø³ÙˆØ§Ù„: Ú©Ø¯Ø§Ù… Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø§Ø³ØªØŸ
Ø¬ÙˆØ§Ø¨ Ø¨Ø¯ÙˆÙ† calibration: Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…! ğŸ¤·

Ø¬ÙˆØ§Ø¨ Ø¨Ø§ calibration:
  Race A: 2.1 m/s
  Race B: 2.3 m/s
  â†’ Race B Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø§Ø³Øª âœ…
```

---

#### Ù…Ø´Ú©Ù„ 3: ØªØ­Ù„ÛŒÙ„ Ø¨ÛŒÙˆÙ…Ú©Ø§Ù†ÛŒÚ©ÛŒ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª

**Biomechanics** Ù†ÛŒØ§Ø² Ø¨Ù‡ ÙˆØ§Ø­Ø¯Ù‡Ø§ÛŒ ÙÛŒØ²ÛŒÚ©ÛŒ Ø¯Ø§Ø±Ø¯:
```
Invalid (pixels):
  "avg_velocity = 12.07 px/s"
  â†’ Ú†Ù‚Ø¯Ø± Ø³Ø±ÛŒØ¹ØŸ Ù†Ù…ÛŒâ€ŒØ¯Ø§Ù†ÛŒÙ…!
  â†’ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¨Ø§ Ù…Ù‚Ø§Ù„Ø§Øª Ø¹Ù„Ù…ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ú©Ø±Ø¯
  â†’ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¨Ù‡ ÙˆØ±Ø²Ø´Ú©Ø§Ø± ØªÙˆØµÛŒÙ‡ Ø¯Ø§Ø¯

Valid (meters):
  "avg_velocity = 2.34 m/s"
  â†’ World record: 2.67 m/s (5.0s for 15m)
  â†’ You are 88% of world record! âœ…
  â†’ Recommendation: increase explosive power in middle section
```

---

### 1.3. Ø±Ø§Ù‡â€ŒØ­Ù„: IFSC Calibration

**Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú¯ÛŒØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯**:

IFSC Ø¯ÛŒÙˆØ§Ø±Ù‡ Ø³Ø±Ø¹ØªÛŒ standard Ø¯Ø§Ø±Ø¯:
- 15 Ù…ØªØ± Ø§Ø±ØªÙØ§Ø¹
- 3 Ù…ØªØ± Ø¹Ø±Ø¶
- **31 Ú¯ÛŒØ±Ù‡ Ù‚Ø±Ù…Ø²** Ø¨Ø§ Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚ Ø´Ù†Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡

```python
# IFSC Route Map
holds = {
    1: {'x': 0.75m, 'y': 0.5m},
    2: {'x': 2.25m, 'y': 1.0m},
    # ...
    31: {'x': 1.5m, 'y': 14.5m}  # top hold
}
```

**ÙØ±Ø¢ÛŒÙ†Ø¯ calibration**:
```
1. Detect holds in video frame (red color detection)
2. Match detected holds to known IFSC holds
3. Compute homography matrix (pixel â†” meter)
4. Use homography to convert any pixel coordinate to meters
```

**Ù…Ø«Ø§Ù„**:
```python
from calibration.camera_calibration import CameraCalibrator

# Load IFSC route map
route_map = IFSCRouteMap.load_from_json("configs/ifsc_route_coordinates.json")

# Detect holds in frame
holds_detected = hold_detector.detect(frame)

# Calibrate
calibrator = CameraCalibrator(route_map)
result = calibrator.calibrate(frame, holds_detected)

# Convert pixel to meter
pixel_coord = (480, 320)
meter_coord = result.pixel_to_meter_func(pixel_coord[0], pixel_coord[1])
# â†’ (1.2m, 8.5m) âœ…
```

---

### 1.4. Ú†Ø§Ù„Ø´: Ø¯ÙˆØ±Ø¨ÛŒÙ† Ù…ØªØ­Ø±Ú©

**Ø³Ø§Ø¯Ù‡â€ŒØªØ±ÛŒÙ† calibration**: ÛŒÚ© Ø¨Ø§Ø± Ø¯Ø± Ø§ÙˆÙ„ ÙˆÛŒØ¯Ø¦Ùˆ
```python
# Frame 1:
calibration = calibrate_frame(frame_1)

# Use for all frames:
for frame in video:
    meters = calibration.pixel_to_meter(pixels)  # âŒ WRONG for moving camera!
```

**Ú†Ø±Ø§ Ú©Ø§Ø± Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ**
- Frame 1: calibration Ø¨Ø±Ø§ÛŒ wide view
- Frame 143: calibration Ø¨Ø±Ø§ÛŒ zoomed view
- **Ø¯Ùˆ calibration Ú©Ø§Ù…Ù„Ø§Ù‹ Ù…ØªÙØ§ÙˆØª Ù‡Ø³ØªÙ†Ø¯!**

**Ø±Ø§Ù‡â€ŒØ­Ù„: PeriodicCalibrator**
```python
# Recalibrate every 30 frames (1 second)
calibrator = PeriodicCalibrator(recalibration_interval=30)

for frame_id, frame in enumerate(video):
    # Auto-recalibrates every 30 frames
    calibration = calibrator.calibrate_frame(frame, frame_id)

    # Use calibration for this frame
    meters = calibration.pixel_to_meter(pixels)  # âœ… CORRECT!
```

**Ù…Ø²Ø§ÛŒØ§**:
- Adapts to camera movement
- Caches calibration (30Ã— faster than per-frame)
- Temporal smoothing (reduces jitter)
- Automatic fallback if calibration fails

---

## Ø¨Ø®Ø´ 2: Ú†Ø±Ø§ Frame Selection Ù…Ù‡Ù… Ø§Ø³ØªØŸ

### 2.1. Ø³Ø§Ø®ØªØ§Ø± ÙˆÛŒØ¯Ø¦ÙˆÙ‡Ø§ÛŒ Ù…Ø³Ø§Ø¨Ù‚Ù‡

**Ù‡Ø± race segment Ø´Ø§Ù…Ù„ 3 Ø¨Ø®Ø´ Ø§Ø³Øª**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Race Segment Video (4.77s)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Pre-race   â”‚   RACE      â”‚   Post-race          â”‚
â”‚ 1.5s       â”‚   1.77s     â”‚   1.5s               â”‚
â”‚ (45 frames)â”‚  (53 frames)â”‚  (45 frames)         â”‚
â”‚            â”‚             â”‚                      â”‚
â”‚ Standing   â”‚ Climbing    â”‚ Finished             â”‚
â”‚ Preparing  â”‚ (THE DATA!) â”‚ Celebrating          â”‚
â”‚ v â‰ˆ 0      â”‚ v = 2.5 m/s â”‚ v â‰ˆ 0                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Buffer Ú†Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡ØŸ**
- Ø§Ø­ØªÛŒØ§Ø· Ø¨Ø±Ø§ÛŒ late starts (Ø¨Ø¹Ø¶ÛŒ Ù…Ø³Ø§Ø¨Ù‚Ø§Øª 1-2s ØªØ£Ø®ÛŒØ± Ø¯Ø§Ø±Ù†Ø¯)
- Ù…Ø·Ù…Ø¦Ù† Ø´Ø¯Ù† Ú©Ù‡ Ø´Ø±ÙˆØ¹/Ù¾Ø§ÛŒØ§Ù† Ú©Ø§Ù…Ù„ capture Ø´ÙˆØ¯

---

### 2.2. Ù…Ø´Ú©Ù„: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÙˆÛŒ Ù‡Ù…Ù‡ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§

**ÙØ¹Ù„Ø§Ù‹ `performance_metrics.py` Ú†ÛŒÚ©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ**

```python
# Load pose file (all 143 frames)
frames = load_pose_json(pose_file)

# Process ALL frames:
for frame in frames:  # âŒ includes pre/post!
    com = calculate_center_of_mass(frame)
    velocity = calculate_velocity(com)
    # ...

avg_velocity = mean(all_velocities)
```

**Ù†ØªÛŒØ¬Ù‡**:
```python
velocities = [
    0, 0, 0, ...,  # Pre-race (45 frames) - standing still
    2.5, 2.4, 2.6, ...,  # Race (53 frames) - climbing fast!
    0.1, 0, 0, ...  # Post-race (45 frames) - stopped
]

avg_velocity = mean(velocities)
             = (0*45 + 2.5*53 + 0*45) / 143
             = 132.5 / 143
             = 0.93 m/s  # âŒ 2.7Ã— too low!

correct_avg = mean(velocities[45:98])  # race frames only
            = 2.5 m/s  # âœ…
```

**Ø®Ø·Ø§: 2.7Ã— underestimation!**

---

### 2.3. ØªØ§Ø«ÛŒØ± Ø±ÙˆÛŒ metrics Ø¯ÛŒÚ¯Ø±

#### Path Length
```python
# WITH pre/post frames (WRONG):
path = [
    (0, 0), (0.1, 0.2), ...,  # pre-race movement (adjusting position)
    (0, 0.5), (0, 1.5), ...,  # race (climbing upward)
    (0.2, 15), (0.3, 15), ... # post-race (lateral movement)
]
path_length = sum(distances) = 18.5m  # âŒ too long

# WITHOUT pre/post (CORRECT):
path = [
    (0, 0.5), (0, 1.5), ...,  # race only
]
path_length = sum(distances) = 15.8m  # âœ… realistic
```

#### Path Efficiency
```python
# WRONG:
efficiency = straight_distance / path_length
           = 15.0 / 18.5
           = 0.81  # seems okay?

# BUT straight_distance is also wrong!
# It's from first frame (pre-race) to last frame (post-race)
# NOT from race start to race finish

# CORRECT:
straight_distance = 15.0m  # race start to finish
path_length = 15.8m  # actual climbing path
efficiency = 15.0 / 15.8 = 0.95  # âœ… excellent!
```

---

### 2.4. Ø±Ø§Ù‡â€ŒØ­Ù„: ÙÛŒÙ„ØªØ± ÙØ±ÛŒÙ…â€ŒÙ‡Ø§

**Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Race Boundaries**:

Race boundaries Ø¯Ø± metadata Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯:
```json
// data/race_segments/chamonix_2024/Speed_finals_Chamonix_2024_race001_metadata.json
{
  "detected_start_frame": 11784,  // Ø´Ø±ÙˆØ¹ ÙˆØ§Ù‚Ø¹ÛŒ Ù…Ø³Ø§Ø¨Ù‚Ù‡
  "detected_finish_frame": 11837,  // Ù¾Ø§ÛŒØ§Ù† ÙˆØ§Ù‚Ø¹ÛŒ Ù…Ø³Ø§Ø¨Ù‚Ù‡
  "start_frame": 11739,  // Ø´Ø±ÙˆØ¹ segment (Ø¨Ø§ buffer)
  // ...
}
```

**ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ pose file frame IDs**:
```python
# Pose file frame IDs start from 0
# Metadata frame IDs are from original video

segment_start = metadata['start_frame']  # 11739
race_start = metadata['detected_start_frame']  # 11784
race_end = metadata['detected_finish_frame']  # 11837

# Convert to pose file coordinates:
pose_race_start = race_start - segment_start  # 11784 - 11739 = 45 âœ…
pose_race_end = race_end - segment_start  # 11837 - 11739 = 98 âœ…
```

**Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± metrics**:
```python
for frame in frames:
    frame_id = frame['frame_id']

    # Filter by race boundaries
    if frame_id < pose_race_start:
        continue  # skip pre-race
    if frame_id > pose_race_end:
        break  # skip post-race

    # Process only race frames
    com = calculate_center_of_mass(frame)
    # ...
```

---

## Ø¨Ø®Ø´ 3: Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø³ÛŒØ³ØªÙ…

### 3.1. Ù†Ù‚Ø´Ù‡ Ú©Ø§Ù…Ù„: Ø§Ø² ÙˆÛŒØ¯Ø¦Ùˆ ØªØ§ Metrics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Race Video  â”‚ (MP4, 4.77s, 143 frames)
â”‚ (segment)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pose Extraction â”‚ (BlazePose)
â”‚  (Phase 2)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pose JSON          â”‚ (143 frames, 33 keypoints each)
â”‚ + Metadata JSON    â”‚ (race boundaries, athlete info)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                  â”‚
       â–¼                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hold Detection  â”‚              â”‚ Load Race        â”‚
â”‚ (HSV color)     â”‚              â”‚ Boundaries       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                  â”‚
       â–¼                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚ Camera           â”‚                     â”‚
â”‚ Calibration      â”‚                     â”‚
â”‚ (Homography)     â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
       â”‚                                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Performance       â”‚
            â”‚ Metrics           â”‚
            â”‚ Calculator        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Metrics JSON      â”‚
            â”‚ (calibrated,      â”‚
            â”‚  race-only)       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 3.2. Ú©Ø¬Ø§ Calibration Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŸ

**Inside PerformanceAnalyzer.analyze_pose_file()**:

```python
def analyze_pose_file(
    self,
    pose_json_path,
    lane='left',
    calibration_path=None,  # â† calibration input
    start_frame=None,       # â† race boundary
    end_frame=None          # â† race boundary
):
    # 1. Load calibration if provided
    calibration = None
    if calibration_path and calibration_path.exists():
        calibration = CameraCalibrator.load_calibration(calibration_path)

    # 2. Load pose data
    frames = load_pose_json(pose_json_path)

    # 3. Process frames (with filtering + calibration)
    com_positions = []

    for frame in frames:
        frame_id = frame['frame_id']

        # FRAME FILTERING:
        if start_frame is not None and frame_id < start_frame:
            continue  # skip pre-race
        if end_frame is not None and frame_id > end_frame:
            break  # skip post-race

        # Calculate COM in pixels
        com_x_px, com_y_px = self.calculate_com(frame['keypoints'])

        # CALIBRATION:
        if calibration:
            # Convert pixel â†’ meter
            com_x_m, com_y_m = calibration.pixel_to_meter_func(com_x_px, com_y_px)
            com_positions.append((com_x_m, com_y_m))
        else:
            # Keep in pixels (no calibration)
            com_positions.append((com_x_px, com_y_px))

    # 4. Calculate metrics (velocity, path length, etc.)
    # Units will be m/s (if calibrated) or px/s (if not)
    metrics = self.calculate_metrics(com_positions)

    # 5. Return
    return metrics
```

**Ù†Ú©ØªÙ‡ Ú©Ù„ÛŒØ¯ÛŒ**: calibration Ùˆ frame filtering **inside** performance_metrics.py Ø§ØªÙØ§Ù‚ Ù…ÛŒâ€ŒØ§ÙØªØ¯ØŒ Ù†Ù‡ Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯ Ø¢Ù†!

---

### 3.3. Ú©Ø¬Ø§ Frame Boundaries load Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ØŸ

**Inside batch_calculate_metrics.py**:

```python
def calculate_race_metrics(self, pose_file, lane='left'):
    # 1. Find calibration file
    cal_file = self.calibration_dir / competition / f"{race_name}_calibration.json"

    # 2. Load race metadata
    metadata_path = self.race_segments_dir / competition / f"{race_name}_metadata.json"

    start_frame = None
    end_frame = None

    if metadata_path.exists():
        with open(metadata_path) as f:
            metadata = json.load(f)

        # Extract race boundaries
        start_frame_orig = metadata.get('detected_start_frame')
        end_frame_orig = metadata.get('detected_finish_frame')
        segment_start = metadata.get('start_frame')

        # Convert to pose file frame IDs
        if start_frame_orig and segment_start:
            start_frame = start_frame_orig - segment_start
        if end_frame_orig and segment_start:
            end_frame = end_frame_orig - segment_start

    # 3. Call performance_metrics with both
    metrics = self.analyzer.analyze_pose_file(
        pose_file,
        lane=lane,
        calibration_path=cal_file if cal_file.exists() else None,
        start_frame=start_frame,
        end_frame=end_frame
    )

    return metrics
```

---

## Ø¨Ø®Ø´ 4: Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„

### 4.1. Modification Ø¨Ù‡ performance_metrics.py

**Ù‚Ø¨Ù„**:
```python
# src/analysis/performance_metrics.py (Ø®Ø· ~237)

def analyze_pose_file(
    self,
    pose_json_path: Path,
    lane: str = 'left',
    min_visibility: float = 0.5,
    calibration_path: Optional[Path] = None
) -> Optional[PerformanceMetrics]:
```

**Ø¨Ø¹Ø¯**:
```python
def analyze_pose_file(
    self,
    pose_json_path: Path,
    lane: str = 'left',
    min_visibility: float = 0.5,
    calibration_path: Optional[Path] = None,
    start_frame: Optional[int] = None,      # NEW
    end_frame: Optional[int] = None,        # NEW
    race_metadata: Optional[Dict] = None   # NEW (optional)
) -> Optional[PerformanceMetrics]:
    """
    Analyze pose data and calculate performance metrics.

    Args:
        pose_json_path: Path to pose JSON file
        lane: 'left' or 'right'
        min_visibility: Minimum keypoint visibility threshold
        calibration_path: Path to calibration JSON (optional)
        start_frame: First frame of race period (optional)
        end_frame: Last frame of race period (optional)
        race_metadata: Full race metadata dict (optional)

    Returns:
        PerformanceMetrics object or None if failed
    """
```

**ÙÛŒÙ„ØªØ± ÙØ±ÛŒÙ…â€ŒÙ‡Ø§** (Ø®Ø· ~289):
```python
# Track filtering statistics
frames_total = len(frames)
frames_skipped_pre = 0
frames_skipped_post = 0
frames_analyzed = 0

for frame in frames:
    frame_id = frame.get('frame_id', 0)

    # Filter by race boundaries
    if start_frame is not None and frame_id < start_frame:
        frames_skipped_pre += 1
        continue  # Skip pre-race frames

    if end_frame is not None and frame_id > end_frame:
        frames_skipped_post += 1
        continue  # Skip post-race frames (or break for efficiency)

    # Process frame (only race frames)
    climber_data = frame.get(climber_key)
    if not climber_data or not climber_data.get('keypoints'):
        continue

    frames_analyzed += 1
    # ... existing processing code
```

**Ø§Ø¶Ø§ÙÙ‡ metadata Ø¨Ù‡ Ø®Ø±ÙˆØ¬ÛŒ**:
```python
# At the end, before returning:
metrics_dict = metrics.to_dict()

# Add race boundaries info
metrics_dict['race_boundaries'] = {
    'start_frame': start_frame,
    'end_frame': end_frame,
    'total_frames_in_file': frames_total,
    'frames_analyzed': frames_analyzed,
    'frames_skipped_pre': frames_skipped_pre,
    'frames_skipped_post': frames_skipped_post
}

return metrics_dict
```

---

### 4.2. Modification Ø¨Ù‡ batch_calculate_metrics.py

**Location**: `scripts/batch_calculate_metrics.py` (Ø®Ø· ~94)

**Ù‚Ø¨Ù„**:
```python
metrics = self.analyzer.analyze_pose_file(
    pose_file,
    lane=lane,
    calibration_path=cal_file if cal_file.exists() else None
)
```

**Ø¨Ø¹Ø¯**:
```python
# Load race metadata
metadata_path = pose_file.parent.parent.parent / "race_segments" / competition / f"{race_name}_metadata.json"

start_frame = None
end_frame = None
race_metadata = None

if metadata_path.exists():
    try:
        with open(metadata_path, 'r', encoding='utf-8') as f:
            race_metadata = json.load(f)

        # Extract race boundaries (original video frame IDs)
        start_frame_orig = race_metadata.get('detected_start_frame')
        end_frame_orig = race_metadata.get('detected_finish_frame')
        segment_start = race_metadata.get('start_frame')

        # Convert to pose file frame IDs (0-indexed)
        if start_frame_orig is not None and segment_start is not None:
            start_frame = start_frame_orig - segment_start

        if end_frame_orig is not None and segment_start is not None:
            end_frame = end_frame_orig - segment_start

        logger.info(f"  Race boundaries: start={start_frame}, end={end_frame}")

    except Exception as e:
        logger.warning(f"  Failed to load metadata: {e}")
else:
    logger.warning(f"  Metadata not found: {metadata_path} - processing all frames")

# Calculate metrics with calibration + race boundaries
metrics = self.analyzer.analyze_pose_file(
    pose_file,
    lane=lane,
    calibration_path=cal_file if cal_file.exists() else None,
    start_frame=start_frame,
    end_frame=end_frame,
    race_metadata=race_metadata
)
```

---

### 4.3. Ø³Ø§Ø®Øª batch_calibration.py

**(Ú©Ø¯ Ú©Ø§Ù…Ù„ Ø¯Ø± PROMPT_FOR_UI_FIX_METRICS.md Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª)**

**Ø®Ù„Ø§ØµÙ‡**:
```python
class BatchCalibrator:
    def __init__(self, race_segments_dir, output_dir, ifsc_map_path):
        # Load IFSC route map (31 holds)
        # Create HoldDetector
        # Setup output directory

    def calibrate_race(self, video_path, output_path):
        # Open video
        # Create PeriodicCalibrator
        # Process all frames
        # Save calibration JSON
        # Return statistics

    def run(self, competition=None, max_races=None):
        # Find all race videos
        # Calibrate each
        # Save summary
```

**Ø§Ø³ØªÙØ§Ø¯Ù‡**:
```bash
# Test with 5 races
python scripts/batch_calibration.py --test

# Full batch (188 races)
python scripts/batch_calibration.py
```

---

## Ø¨Ø®Ø´ 5: ØªØ³Øª Ùˆ Validation

### 5.1. ØªØ³Øª Ù…Ø±Ø­Ù„Ù‡ Ø¨Ù‡ Ù…Ø±Ø­Ù„Ù‡

#### Test 1: Frame Selection Only (Ø¨Ø¯ÙˆÙ† calibration)

```bash
# Modify code
# Test with 1 race
python scripts/batch_calculate_metrics.py --max-races 1 --competition chamonix_2024 --force

# Check output
cat data/processed/metrics/chamonix_2024/Speed_finals_Chamonix_2024_race001_metrics_left.json
```

**Ú†Ú©â€ŒÙ„ÛŒØ³Øª**:
- [x] `race_boundaries` field exists
- [x] `frames_analyzed` < `total_frames_in_file`
- [x] velocity **2-3Ã— higher** than before
- [x] efficiency **higher** than before
- [x] No crashes or errors

---

#### Test 2: Calibration Only (Ø¨Ø¯ÙˆÙ† frame filtering)

```bash
# Temporarily disable frame filtering in code
# Run calibration
python scripts/batch_calibration.py --test

# Check calibration file
cat data/processed/calibration/chamonix_2024/Speed_finals_Chamonix_2024_race001_calibration.json
```

**Ú†Ú©â€ŒÙ„ÛŒØ³Øª**:
- [x] Calibration JSON created
- [x] RMSE < 10cm (ideally < 5cm)
- [x] holds_detected >= 4 for most frames
- [x] holds_used >= 4
- [x] inlier_ratio > 0.7

---

#### Test 3: Both Combined

```bash
# Re-enable frame filtering
# Run full pipeline on 5 races
python scripts/batch_calculate_metrics.py --max-races 5 --competition chamonix_2024 --force

# Check metrics
for f in data/processed/metrics/chamonix_2024/*_left.json; do
    echo "=== $f ==="
    jq '.is_calibrated, .units, .summary.avg_vertical_velocity, .race_boundaries.frames_analyzed' "$f"
done
```

**Expected output**:
```json
true
"meters"
2.34
53
```

---

### 5.2. Validation Metrics

#### Velocity Range Check

```python
# scripts/validate_metrics.py

import json
from pathlib import Path

for metrics_file in Path("data/processed/metrics").glob("*/*_metrics_*.json"):
    with open(metrics_file) as f:
        data = json.load(f)

    v = data['summary']['avg_vertical_velocity']

    # World record: ~2.67 m/s (5.0s for 15m)
    # Elite: 2.0-2.8 m/s
    # Amateur: 1.0-1.8 m/s
    # Suspicious: < 0.5 or > 5.0 m/s

    if v < 0.5 or v > 5.0:
        print(f"âŒ OUTLIER: {metrics_file.name} - velocity = {v:.2f} m/s")
    elif 2.0 <= v <= 2.8:
        print(f"âœ… ELITE: {metrics_file.name} - velocity = {v:.2f} m/s")
    elif 1.0 <= v < 2.0:
        print(f"âœ… GOOD: {metrics_file.name} - velocity = {v:.2f} m/s")
    else:
        print(f"âš ï¸ CHECK: {metrics_file.name} - velocity = {v:.2f} m/s")
```

---

#### Path Efficiency Check

```python
for metrics_file in Path("data/processed/metrics").glob("*/*_metrics_*.json"):
    with open(metrics_file) as f:
        data = json.load(f)

    eff = data['summary']['path_efficiency']

    # Realistic range: 0.6-0.95
    # Perfect straight line: 1.0 (impossible)
    # Very inefficient: < 0.5

    if eff < 0.4 or eff > 0.98:
        print(f"âŒ OUTLIER: {metrics_file.name} - efficiency = {eff:.2f}")
    elif 0.8 <= eff <= 0.95:
        print(f"âœ… EXCELLENT: {metrics_file.name} - efficiency = {eff:.2f}")
    elif 0.6 <= eff < 0.8:
        print(f"âœ… GOOD: {metrics_file.name} - efficiency = {eff:.2f}")
    else:
        print(f"âš ï¸ CHECK: {metrics_file.name} - efficiency = {eff:.2f}")
```

---

### 5.3. Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯

```python
# scripts/compare_old_new.py

import pandas as pd

old_metrics = load_metrics("data/processed/metrics_old_INVALID")
new_metrics = load_metrics("data/processed/metrics")

comparison = pd.DataFrame({
    'race': [m['race_name'] for m in new_metrics],
    'old_velocity': [m_old['summary']['avg_vertical_velocity'] for m_old in old_metrics],
    'new_velocity': [m_new['summary']['avg_vertical_velocity'] for m_new in new_metrics],
    'velocity_ratio': [new/old for new, old in zip(new_velocities, old_velocities)],
    'old_calibrated': [m_old.get('is_calibrated', False) for m_old in old_metrics],
    'new_calibrated': [m_new.get('is_calibrated', False) for m_new in new_metrics]
})

print(comparison.describe())
```

**Expected results**:
```
velocity_ratio:
  count: 188
  mean:  8.5    (8.5Ã— improvement)
  std:   2.3
  min:   4.2
  max:   15.3

new_calibrated:
  True: 188 (100%)
  False: 0
```

---

## Ø¨Ø®Ø´ 6: Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ

### 6.1. Ù…Ø´Ú©Ù„Ø§Øª Ù…ØªØ¯Ø§ÙˆÙ„ Frame Selection

#### Problem: Frame IDs don't match

**Ø¹Ù„Ø§Ù…Øª**:
```
WARNING: start_frame=11784 but pose file only has 143 frames!
All frames skipped, no metrics calculated
```

**Ø¹Ù„Øª**: frame IDs Ø§Ø´ØªØ¨Ø§Ù‡ convert Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯

**Ø±Ø§Ù‡â€ŒØ­Ù„**:
```python
# Check metadata:
print(f"detected_start_frame: {metadata['detected_start_frame']}")
print(f"start_frame (segment): {metadata['start_frame']}")

# Correct conversion:
pose_start = metadata['detected_start_frame'] - metadata['start_frame']

# NOT:
pose_start = metadata['detected_start_frame']  # âŒ WRONG!
```

---

#### Problem: frames_analyzed = 0

**Ø¹Ù„Øª**: boundaries Ø®ÛŒÙ„ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ù‡Ø³ØªÙ†Ø¯ ÛŒØ§ Ø§Ø´ØªØ¨Ø§Ù‡

**Ø±Ø§Ù‡â€ŒØ­Ù„**:
```python
# Debug output:
logger.info(f"Total frames: {len(frames)}")
logger.info(f"start_frame: {start_frame}, end_frame: {end_frame}")
logger.info(f"Frame IDs in pose file: {frames[0]['frame_id']} to {frames[-1]['frame_id']}")

# If start/end are out of range, use fallback:
if start_frame is None or start_frame < 0:
    start_frame = 0
if end_frame is None or end_frame >= len(frames):
    end_frame = len(frames) - 1
```

---

### 6.2. Ù…Ø´Ú©Ù„Ø§Øª Ù…ØªØ¯Ø§ÙˆÙ„ Calibration

#### Problem: Hold detection fails (< 4 holds)

**Ø¹Ù„Øª**: HSV thresholds Ø®ÛŒÙ„ÛŒ Ù…Ø­Ø¯ÙˆØ¯

**Ø±Ø§Ù‡â€ŒØ­Ù„**:
```python
# Lower min_confidence:
hold_detector = HoldDetector(
    min_confidence=0.15,  # was 0.2
    min_area=30           # was 50
)

# Or adjust HSV range (src/phase1_pose_estimation/hold_detector.py):
lower_red1 = np.array([0, 100, 50])    # was [0, 120, 70]
upper_red1 = np.array([10, 255, 255])  # was [10, 255, 255]
```

---

#### Problem: RMSE > 10cm

**Ø¹Ù„Øª**:
- Not enough holds detected
- Outlier hold matches
- Camera angle extreme

**Ø±Ø§Ù‡â€ŒØ­Ù„**:
```python
# Use PeriodicCalibrator with outlier rejection:
calibrator = PeriodicCalibrator(
    route_map=route_map,
    hold_detector=hold_detector,
    recalibration_interval=30,
    rmse_threshold=0.10,  # Reject if RMSE > 10cm
    fallback_to_previous=True  # Use previous calibration if current fails
)
```

---

#### Problem: Video won't open

**Ø¹Ù„à¦¤**: path Ø§Ø´ØªØ¨Ø§Ù‡ ÛŒØ§ ÙØ§ÛŒÙ„ Ø®Ø±Ø§Ø¨

**Ø±Ø§Ù‡â€ŒØ­Ù„**:
```python
import cv2

cap = cv2.VideoCapture(str(video_path))
if not cap.isOpened():
    # Try absolute path:
    abs_path = video_path.resolve()
    cap = cv2.VideoCapture(str(abs_path))

    if not cap.isOpened():
        # Check if file exists:
        if not video_path.exists():
            raise FileNotFoundError(f"Video not found: {video_path}")
        else:
            raise RuntimeError(f"Cannot open video (corrupt?): {video_path}")
```

---

### 6.3. Memory Issues

**Problem**: Out of memory during batch processing

**Ø±Ø§Ù‡â€ŒØ­Ù„**: Process Ø¯Ø± chunks

```python
# Instead of:
all_videos = list(Path("data/race_segments").glob("*/*.mp4"))
for video in all_videos:  # âŒ 188 races at once
    process(video)

# Do:
competitions = ["seoul_2024", "villars_2024", ...]
for comp in competitions:
    videos = list(Path(f"data/race_segments/{comp}").glob("*.mp4"))
    for video in videos:  # âœ… ~30 races at a time
        process(video)
```

---

## Ø¨Ø®Ø´ 7: Ù†Ú©Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡

### 7.1. Temporal Smoothing

**Problem**: Calibration jitter Ø¨ÛŒÙ† frameÙ‡Ø§

**Ø±Ø§Ù‡â€ŒØ­Ù„**: PeriodicCalibrator Ø¨Ø§ smoothing

```python
class PeriodicCalibrator:
    def __init__(self, ..., smoothing_window=3):
        self.recent_calibrations = []  # Last N calibrations
        self.smoothing_window = smoothing_window

    def calibrate_frame(self, frame, frame_id):
        # Get raw calibration
        raw_calib = self._calibrate_single_frame(frame)

        # Add to history
        self.recent_calibrations.append(raw_calib)
        if len(self.recent_calibrations) > self.smoothing_window:
            self.recent_calibrations.pop(0)

        # Smooth homography matrix
        smoothed_H = np.mean([c.homography for c in self.recent_calibrations], axis=0)

        # Return smoothed calibration
        return CalibrationResult(
            homography=smoothed_H,
            # ... other fields
        )
```

---

### 7.2. Hold Detection Optimization

**Wall Segmentation**: Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† detection Ø¨Ù‡ Ø¨Ø®Ø´ Ø¯ÛŒÙˆØ§Ø±

```python
def detect_holds_with_wall_mask(frame, wall_mask):
    """
    Detect holds only in wall region (not background/audience).
    """
    # Create mask (wall = white, background = black)
    # ... (using edge detection or manual annotation)

    # Apply mask before color thresholding
    masked_frame = cv2.bitwise_and(frame, frame, mask=wall_mask)

    # Detect holds in masked frame
    holds = hold_detector.detect(masked_frame)

    return holds
```

---

### 7.3. Multi-Scale Detection

**Ù…Ø´Ú©Ù„**: holds Ø¯Ø± frames Ù…Ø®ØªÙ„Ù Ø³Ø§ÛŒØ²Ù‡Ø§ÛŒ Ù…ØªÙØ§ÙˆØª Ø¯Ø§Ø±Ù†Ø¯ (zoom)

**Ø±Ø§Ù‡â€ŒØ­Ù„**: Adaptive thresholds

```python
def adaptive_hold_detection(frame, frame_id, total_frames):
    """
    Adjust detection params based on frame position (zoom level).
    """
    # Estimate zoom (linear approximation)
    zoom_factor = 1.0 + 2.0 * (frame_id / total_frames)  # 1.0 â†’ 3.0

    # Adjust min_area based on zoom
    min_area_adaptive = base_min_area * (zoom_factor ** 2)

    # Detect with adaptive params
    holds = hold_detector.detect(frame, min_area=min_area_adaptive)

    return holds
```

---

### 7.4. Performance Benchmarks

**Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±**:

| Operation | Time per race | Notes |
|-----------|---------------|-------|
| Hold detection | 5-10s | CPU-bound |
| Calibration (single frame) | 0.1-0.5s | Depends on # holds |
| Calibration (periodic, 143 frames) | 2-5s | Cached every 30 frames |
| Metrics calculation (calibrated) | 0.5-1s | Mostly Python overhead |
| **Total per race** | **10-20s** | Full pipeline |

**Ø¨Ø±Ø§ÛŒ 188 races**: 30-60 Ø¯Ù‚ÛŒÙ‚Ù‡ (Ø¨Ø§ parallelization: 10-20 Ø¯Ù‚ÛŒÙ‚Ù‡)

---

## Ø®Ù„Ø§ØµÙ‡ Ùˆ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ

### Ú†ÛŒØ²Ù‡Ø§ÛŒÛŒ Ú©Ù‡ ÛŒØ§Ø¯ Ú¯Ø±ÙØªÛŒÙ…:

1. **Calibration Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª** Ø¨Ø±Ø§ÛŒ:
   - ØªØ¨Ø¯ÛŒÙ„ pixel â†’ meter
   - Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨ÛŒÙ† races
   - ØªØ­Ù„ÛŒÙ„ Ø¨ÛŒÙˆÙ…Ú©Ø§Ù†ÛŒÚ©ÛŒ Ù…Ø¹ØªØ¨Ø±

2. **Frame Selection Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª** Ø¨Ø±Ø§ÛŒ:
   - Ø­Ø°Ù ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ pre/post-race
   - Ù…Ø­Ø§Ø³Ø¨Ù‡ ØµØ­ÛŒØ­ velocity (2-3Ã— improvement)
   - metrics Ù…Ø¹ØªØ¨Ø±

3. **Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ** Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯:
   - Modification Ø¨Ù‡ `performance_metrics.py`
   - Modification Ø¨Ù‡ `batch_calculate_metrics.py`
   - Ø³Ø§Ø®Øª `batch_calibration.py`

4. **Validation** Ø´Ø§Ù…Ù„:
   - Ø¨Ø±Ø±Ø³ÛŒ velocity range (0.5-5.0 m/s)
   - Ø¨Ø±Ø±Ø³ÛŒ efficiency range (0.4-0.98)
   - Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯ (8-10Ã— improvement)

5. **Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ** Ù†ÛŒØ§Ø² Ø¨Ù‡:
   - Debug frame ID conversions
   - Adjust HSV thresholds
   - Handle memory issues Ø¨Ø§ chunking

---

### Ú†Ú©â€ŒÙ„ÛŒØ³Øª Ù†Ù‡Ø§ÛŒÛŒ

**Ù‚Ø¨Ù„ Ø§Ø² production deployment**:
- [ ] Ù‡Ù…Ù‡ 188 race calibrated Ø´Ø¯Ù†Ø¯ (RMSE < 10cm)
- [ ] Ù‡Ù…Ù‡ metrics Ø¨Ø§ frame filtering Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù†Ø¯
- [ ] validation checks passed (velocity, efficiency in range)
- [ ] comparison Ø¨Ø§ old metrics (8-10Ã— improvement)
- [ ] aggregations Ùˆ leaderboards updated
- [ ] documentation Ú©Ø§Ù…Ù„ Ø§Ø³Øª

---

**Ù…ÙˆÙÙ‚ Ø¨Ø§Ø´ÛŒØ¯!** ğŸš€

Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ù‡Ù…Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ø´Ù…Ø§ Ø±Ø§ Ù¾Ø§Ø³Ø® Ø¯Ù‡Ø¯. Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ÛŒ Ù…Ø§Ù†Ø¯Ù‡ØŒ Ø¨Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯:
- `MASTER_CONTEXT.md` - ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡
- `PROMPT_FOR_UI_FIX_METRICS.md` - Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø±Ø§ÛŒ UI
- `docs/SESSION_LOG_PHASE3_TEST.md` - Ú¯Ø²Ø§Ø±Ø´ Ú©Ø´Ù Ù…Ø´Ú©Ù„Ø§Øª

---

**ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡**: 2025-11-15
**ØªÙˆØ³Ø·**: Claude Code
**Ù†Ø³Ø®Ù‡**: 1.0
